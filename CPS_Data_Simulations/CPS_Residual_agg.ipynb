{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 23\u001b[0m\n\u001b[0;32m     20\u001b[0m true_beta1_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_simulations):\n\u001b[1;32m---> 23\u001b[0m     data \u001b[38;5;241m=\u001b[39m process_cps_data(file_path)\n\u001b[0;32m     24\u001b[0m     states \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSTATEFIP\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique()\n\u001b[0;32m     26\u001b[0m     treatment_states \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(states, size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(states), replace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Biswajit Palit\\Research-Module-\\cps_data_agg.py:8\u001b[0m, in \u001b[0;36mprocess_cps_data\u001b[1;34m(file_path)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_cps_data\u001b[39m(file_path):\n\u001b[1;32m----> 8\u001b[0m     df \u001b[38;5;241m=\u001b[39m cps_data(file_path)\n\u001b[0;32m     10\u001b[0m     X \u001b[38;5;241m=\u001b[39m df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHigh School\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMaster\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms Degree\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAGE\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m     11\u001b[0m     y \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mINCWAGE\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Biswajit Palit\\Research-Module-\\cps_data_prep.py:40\u001b[0m, in \u001b[0;36mcps_data\u001b[1;34m(file_path)\u001b[0m\n\u001b[0;32m     36\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mget_dummies(df, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEducation_Category\u001b[39m\u001b[38;5;124m'\u001b[39m], prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, prefix_sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, drop_first\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     38\u001b[0m df \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;241m~\u001b[39m((df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSTATEFIP\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m56\u001b[39m) \u001b[38;5;241m|\u001b[39m (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSTATEFIP\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m11\u001b[39m))]\n\u001b[1;32m---> 40\u001b[0m dummy_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mget_dummies(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSTATEFIP\u001b[39m\u001b[38;5;124m'\u001b[39m], prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSTATEFIP\u001b[39m\u001b[38;5;124m'\u001b[39m, drop_first\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     41\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([df, dummy_df], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     43\u001b[0m df \u001b[38;5;241m=\u001b[39m df[(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAGE\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m25\u001b[39m) \u001b[38;5;241m&\u001b[39m (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAGE\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m)]\n",
      "File \u001b[1;32mc:\\Users\\Biswajit Palit\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\encoding.py:221\u001b[0m, in \u001b[0;36mget_dummies\u001b[1;34m(data, prefix, prefix_sep, dummy_na, columns, sparse, drop_first, dtype)\u001b[0m\n\u001b[0;32m    219\u001b[0m     result \u001b[38;5;241m=\u001b[39m concat(with_dummies, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 221\u001b[0m     result \u001b[38;5;241m=\u001b[39m _get_dummies_1d(\n\u001b[0;32m    222\u001b[0m         data,\n\u001b[0;32m    223\u001b[0m         prefix,\n\u001b[0;32m    224\u001b[0m         prefix_sep,\n\u001b[0;32m    225\u001b[0m         dummy_na,\n\u001b[0;32m    226\u001b[0m         sparse\u001b[38;5;241m=\u001b[39msparse,\n\u001b[0;32m    227\u001b[0m         drop_first\u001b[38;5;241m=\u001b[39mdrop_first,\n\u001b[0;32m    228\u001b[0m         dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m    229\u001b[0m     )\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\Biswajit Palit\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\encoding.py:330\u001b[0m, in \u001b[0;36m_get_dummies_1d\u001b[1;34m(data, prefix, prefix_sep, dummy_na, sparse, drop_first, dtype)\u001b[0m\n\u001b[0;32m    328\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    329\u001b[0m     eye_dtype \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mbool_\n\u001b[1;32m--> 330\u001b[0m dummy_mat \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39meye(number_of_cols, dtype\u001b[38;5;241m=\u001b[39meye_dtype)\u001b[38;5;241m.\u001b[39mtake(codes, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dummy_na:\n\u001b[0;32m    333\u001b[0m     \u001b[38;5;66;03m# reset NaN GH4446\u001b[39;00m\n\u001b[0;32m    334\u001b[0m     dummy_mat[codes \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from cps_data_agg import (process_cps_data)\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "file_path = r'C:\\Users\\Biswajit Palit\\Downloads\\cps_00006.csv.gz'\n",
    "beta1_estimates = []\n",
    "reject_count = 0  # Counter for the number of rejections\n",
    "alpha = 0.05  # Significance level\n",
    "num_simulations = 1000\n",
    "num_individuals = 20\n",
    "bias_values = []\n",
    "squared_error_values = []\n",
    "standard_error_values = []  # List to store standard errors\n",
    "\n",
    "true_beta1_value = 0\n",
    "\n",
    "for _ in range(num_simulations):\n",
    "    data = process_cps_data(file_path)\n",
    "    states = data['STATEFIP'].unique()\n",
    "\n",
    "    treatment_states = np.random.choice(states, size=len(states), replace=False)\n",
    "\n",
    "    # Assign treatment year to each treatment state, staggered between 1985 and 1995\n",
    "    treatment_years = np.random.choice(range(1985, 1995), size=len(treatment_states)//2, replace=True)\n",
    "    state_to_treatment_year = dict(zip(treatment_states, treatment_years))\n",
    "\n",
    "    # Add a treatment column to the DataFrame\n",
    "    data['TREATMENT'] = data.apply(lambda x: 1 if x['STATEFIP'] in treatment_states and x['STATEFIP'] in state_to_treatment_year and x['YEAR'] >= state_to_treatment_year[x['STATEFIP']] else 0, axis=1)\n",
    "\n",
    "    a = state_to_treatment_year.keys()\n",
    "\n",
    "    filtered_df = data[data['STATEFIP'].isin(a)]\n",
    "\n",
    "    # Separate pre-treatment and post-treatment data\n",
    "    pre_treatment_df = filtered_df[filtered_df['TREATMENT'] == 0]\n",
    "    post_treatment_df = filtered_df[filtered_df['TREATMENT'] == 1]\n",
    "\n",
    "    # Calculate the average residuals for pre-treatment and post-treatment periods\n",
    "    avg_residuals_pre_treatment = pre_treatment_df.groupby('STATEFIP')['Residuals'].mean().reset_index()\n",
    "    avg_residuals_post_treatment = post_treatment_df.groupby('STATEFIP')['Residuals'].mean().reset_index()\n",
    "\n",
    "    # Add a 'Treatment' column to indicate the treatment status for each period\n",
    "    avg_residuals_pre_treatment['TREATMENT'] = 0\n",
    "    avg_residuals_post_treatment['TREATMENT'] = 1\n",
    "\n",
    "    # Combine the two DataFrames into a new DataFrame\n",
    "    two_period_panel_df = pd.concat([avg_residuals_pre_treatment, avg_residuals_post_treatment], ignore_index=True)\n",
    "\n",
    "    # Define the dependent and independent variables\n",
    "    state_dummies = pd.get_dummies(two_period_panel_df['STATEFIP'], prefix='State', drop_first=True)\n",
    "\n",
    "    # Convert state dummy variables to int\n",
    "    state_dummies = state_dummies.astype(int)\n",
    "    two_period_panel_df = pd.concat([two_period_panel_df, state_dummies], axis=1)\n",
    "\n",
    "    y = two_period_panel_df['Residuals']\n",
    "    X = two_period_panel_df.drop(columns=['Residuals'])\n",
    "\n",
    "    # Add a constant term (intercept) to the independent variables\n",
    "    X = sm.add_constant(X)\n",
    "\n",
    "    # Fit the regression model\n",
    "    model = sm.OLS(y, X).fit()\n",
    "\n",
    "    # Extract the standard error of the 'Treatment' coefficient\n",
    "    standard_error = model.bse['TREATMENT']\n",
    "    standard_error_values.append(standard_error)\n",
    "\n",
    "    bias = model.params['TREATMENT'] - true_beta1_value\n",
    "    bias_values.append(bias)\n",
    "\n",
    "    squared_error = (model.params['TREATMENT'] - true_beta1_value) ** 2\n",
    "    squared_error_values.append(squared_error)\n",
    "\n",
    "    # Check if null hypothesis for beta1 is rejected\n",
    "    if model.pvalues['TREATMENT'] < alpha:\n",
    "        reject_count += 1\n",
    "\n",
    "    # Store the beta estimate\n",
    "    beta1_estimates.append(model.params['TREATMENT'])\n",
    "\n",
    "type1_error = reject_count / num_simulations\n",
    "average_bias = np.mean(bias_values)\n",
    "average_mse = np.mean(squared_error_values)\n",
    "average_standard_error = np.mean(standard_error_values)\n",
    "\n",
    "# Calculate the standard error of the distribution of beta\n",
    "std_error_beta_distribution = np.std(beta1_estimates)\n",
    "\n",
    "sns.histplot(beta1_estimates, kde=True)\n",
    "plt.xlabel('Beta1 Estimates')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Beta1 Estimates')\n",
    "plt.show()\n",
    "\n",
    "# Calculate the confidence interval\n",
    "confidence_interval = (\n",
    "    np.mean(beta1_estimates) - 1.96 * std_error_beta_distribution,\n",
    "    np.mean(beta1_estimates) + 1.96 * std_error_beta_distribution\n",
    ")\n",
    "\n",
    "# Plot the confidence interval\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(beta1_estimates, bins=30, density=True, color='blue', alpha=0.7)\n",
    "plt.axvline(np.mean(beta1_estimates), color='red', linestyle='dashed', linewidth=2, label='Mean Estimate')\n",
    "plt.axvline(confidence_interval[0], color='green', linestyle='dashed', linewidth=2, label='95% CI')\n",
    "plt.axvline(confidence_interval[1], color='green', linestyle='dashed', linewidth=2)\n",
    "plt.xlabel('Treatment Coefficient Estimate')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Distribution and Confidence Interval of Treatment Coefficient')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Print the results\n",
    "print(f\"Number of times null hypothesis is rejected: {reject_count} out of {num_simulations} simulations\")\n",
    "print(f\"Type 1 Error: {type1_error}\")\n",
    "print(f\"Bias for Coefficient of Treatment (True Value = {true_beta1_value}): {average_bias}\")\n",
    "print(f\"Average MSE for Coefficient of Treatment (True Value = {true_beta1_value}): {average_mse}\")\n",
    "print(f\"Average Standard Error for Coefficient of Treatment: {average_standard_error}\")\n",
    "print(f\"Standard Error of the Distribution of Beta: {std_error_beta_distribution}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
