{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def generate_powercheck_data(N, T, rho, num_individuals, mean=0, std_dev=1):\n",
    "    # Generate random white noise for each individual\n",
    "    white_noise = np.random.normal(mean, std_dev, size=(N, num_individuals, T))\n",
    "\n",
    "    # Initialize the array to store the data\n",
    "    data = np.zeros((N, num_individuals, T))\n",
    "\n",
    "    # Generate the AR(1) process data for each individual\n",
    "    for i in range(N):\n",
    "        for j in range(num_individuals):\n",
    "            for t in range(T):\n",
    "                if t == 0:\n",
    "                    data[i, j, t] = white_noise[i, j, t]\n",
    "                else:\n",
    "                    data[i, j, t] = rho * data[i, j, t - 1] + white_noise[i, j, t]\n",
    "\n",
    "    # Reshape the data array for easier DataFrame creation\n",
    "    reshaped_data = data.reshape((N * num_individuals, T))\n",
    "\n",
    "    # Create a DataFrame with column names as time periods\n",
    "    df = pd.DataFrame(reshaped_data, columns=[f'{t}' for t in range(T)])\n",
    "\n",
    "    # Add a new 'state' column with repeated state values\n",
    "    df['state'] = np.repeat(np.arange(1, N + 1), num_individuals)\n",
    "\n",
    "    # Add a new 'individual' column with repeated individual values\n",
    "    df['individual'] = np.tile(np.arange(1, num_individuals + 1), N)\n",
    "\n",
    "    melted_df = pd.melt(df, id_vars=['state', 'individual'], var_name='time', value_name='value')\n",
    "\n",
    "    # Convert the 'time' column to int\n",
    "    melted_df['time'] = melted_df['time'].astype(int)\n",
    "\n",
    "    data = melted_df.copy()\n",
    "\n",
    "    data['time'] = data['time'].astype(int)\n",
    "    # Create state dummy variables\n",
    "    state_dummies = pd.get_dummies(data['state'], prefix='state', drop_first = True)\n",
    "\n",
    "    # Convert state dummy variables to int\n",
    "    state_dummies = state_dummies.astype(int)\n",
    "\n",
    "    # Create time dummy variables\n",
    "    time_dummies = pd.get_dummies(data['time'].astype(int), prefix='time', drop_first = True)\n",
    "\n",
    "    # Convert time dummy variables to int\n",
    "    time_dummies = time_dummies.astype(int)\n",
    "\n",
    "    data = pd.concat([data, state_dummies, time_dummies], axis=1)\n",
    "\n",
    "    states = data['state'].unique()\n",
    "\n",
    "    # Randomly select half of the states to be in the treatment group\n",
    "    \n",
    "    treatment_states = np.random.choice(states, size=len(states)//2, replace=False)\n",
    "\n",
    "    # Assign treatment year to each treatment state, staggered between 1985 and 1995\n",
    "    treatment_years = np.random.choice(range(5, 15), size=len(treatment_states), replace=True)\n",
    "    state_to_treatment_year = dict(zip(treatment_states, treatment_years))\n",
    "\n",
    "    # Add a treatment column to the DataFrame\n",
    "    data['TREATMENT'] = data.apply(lambda x: 1 if x['state'] in treatment_states and x['time'] >= state_to_treatment_year[x['state']] else 0, axis=1)\n",
    "    data['outcome'] = data.apply(lambda x: x['value']*(1.02) if x['TREATMENT'] == 1 else x['value'], axis=1)\n",
    "   \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type I Error Rate: 0.1075\n",
      "Average Power: 0.4095125571868492\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as stats\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "def beta_Ztest_twosided(n, alpha, sigma, mu_0, mu):\n",
    "    # (1-alpha/2)-quantile of N(0,1):\n",
    "    z_upper = stats.norm.ppf(1 - alpha/2)\n",
    "    \n",
    "    # location shift under H_1:\n",
    "    location_shift = np.sqrt(n) * (mu - mu_0) / sigma\n",
    "    \n",
    "    # compute power\n",
    "    power = 1 - stats.norm.cdf(z_upper - location_shift)\n",
    "    \n",
    "    return power\n",
    "\n",
    "beta1_estimates = []\n",
    "reject_count = 0  # Counter for the number of rejections\n",
    "reject_count1 = 0\n",
    "alpha = 0.05  # Significance level\n",
    "num_simulations = 400\n",
    "bias_values = []\n",
    "squared_error_values = []\n",
    "N = 50\n",
    "T = 20\n",
    "rho = 0.2\n",
    "num_individuals = 100\n",
    "\n",
    "true_beta1_value = 0\n",
    "standard_error_values = []\n",
    "power_values = []  # Store the power values for each iteration\n",
    "\n",
    "for _ in range(num_simulations):\n",
    "    data = generate_powercheck_data(N, T, rho, num_individuals)\n",
    "\n",
    "    # Step 3: Perform the OLS regression\n",
    "    X = data[['TREATMENT', 'state_2', 'state_3', 'state_4', 'state_5',\n",
    "              'state_6', 'state_7', 'state_8', 'state_9', 'state_10', 'state_11',\n",
    "              'state_12', 'state_13', 'state_14', 'state_15', 'state_16', 'state_17',\n",
    "              'state_18', 'state_19', 'state_20', 'state_21', 'state_22', 'state_23',\n",
    "              'state_24', 'state_25', 'state_26', 'state_27', 'state_28', 'state_29',\n",
    "              'state_30', 'state_31', 'state_32', 'state_33', 'state_34', 'state_35',\n",
    "              'state_36', 'state_37', 'state_38', 'state_39', 'state_40', 'state_41',\n",
    "              'state_42', 'state_43', 'state_44', 'state_45', 'state_46', 'state_47',\n",
    "              'state_48', 'state_49', 'state_50', 'time_1', 'time_2', 'time_3',\n",
    "              'time_4', 'time_5', 'time_6', 'time_7', 'time_8', 'time_9', 'time_10',\n",
    "              'time_11', 'time_12', 'time_13', 'time_14', 'time_15', 'time_16',\n",
    "              'time_17', 'time_18', 'time_19']]  # plus any other control variables\n",
    "    X = sm.add_constant(X)\n",
    "    Y = data['value']  # Replace 'outcome' with your dependent variable\n",
    "    model = sm.OLS(Y, X).fit()\n",
    "\n",
    "    standard_error = model.bse['TREATMENT']\n",
    "    standard_error_values.append(standard_error)\n",
    "\n",
    "    beta1_estimates.append(model.params['TREATMENT'])\n",
    "\n",
    "    # Check if null hypothesis for beta1 is rejected\n",
    "    if model.pvalues['TREATMENT'] < alpha:\n",
    "        reject_count += 1\n",
    "\n",
    "    # Calculate and store the statistical power for each iteration\n",
    "    power = beta_Ztest_twosided(N, alpha, standard_error, true_beta1_value, model.params['TREATMENT'])\n",
    "    power_values.append(power)\n",
    "\n",
    "type1_error = reject_count / num_simulations\n",
    "average_power = np.mean(power_values)\n",
    "print(f\"Type I Error Rate: {type1_error}\")\n",
    "print(f\"Average Power: {average_power}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
