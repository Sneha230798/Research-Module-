{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def generate_ar1_data(N, T, rho, mean=0, std_dev=1):\n",
    "    # Generate random white noise\n",
    "    white_noise = np.random.normal(mean, std_dev, size=(N, T))\n",
    "\n",
    "    # Initialize the array to store the data\n",
    "    data = np.zeros((N, T))\n",
    "\n",
    "    # Generate the AR(1) process data\n",
    "    for i in range(N):\n",
    "        for t in range(T):\n",
    "            if t == 0:\n",
    "                data[i, t] = white_noise[i, t]\n",
    "            else:\n",
    "                data[i, t] = rho * data[i, t - 1] + white_noise[i, t]\n",
    "\n",
    "    # Create a DataFrame with column names as time periods\n",
    "    df = pd.DataFrame(data, columns=[f'{t}' for t in range(T)])\n",
    "\n",
    "    # Add a new 'state' column with random numbers between 1 and N\n",
    "    df['state'] = np.arange(1, N + 1)\n",
    "\n",
    "    melted_df = pd.melt(df, id_vars=['state'], var_name='time', value_name='value')\n",
    "    \n",
    "    \n",
    "    data = melted_df.copy()\n",
    "\n",
    "    data['time'] = data['time'].astype(int)\n",
    "    # Create state dummy variables\n",
    "    state_dummies = pd.get_dummies(data['state'], prefix='state', drop_first = True)\n",
    "\n",
    "    # Convert state dummy variables to int\n",
    "    state_dummies = state_dummies.astype(int)\n",
    "\n",
    "    # Create time dummy variables\n",
    "    time_dummies = pd.get_dummies(data['time'].astype(int), prefix='time', drop_first = True)\n",
    "\n",
    "    # Convert time dummy variables to int\n",
    "    time_dummies = time_dummies.astype(int)\n",
    "\n",
    "    # Concatenate the dummy variables with the original DataFrame\n",
    "    data = pd.concat([data, state_dummies, time_dummies], axis=1)\n",
    "\n",
    "    return data\n",
    "\n",
    "# Example usage:\n",
    "N = 50\n",
    "T = 20\n",
    "rho = 0.5  # Set your desired autoregressive coefficient\n",
    "generated_data = generate_ar1_data(N, T, rho)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of times null hypothesis is rejected for 0.6: 54 out of 1000 simulations\n",
      "Type 1 Error: 0.054\n",
      "Bias for Coefficient of Treatment (True Value = 0): -0.005828054621751731\n",
      "Average MSE for Coefficient of Treatment (True Value = 0): 0.0005666982162468618\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "beta1_estimates = []\n",
    "reject_count = 0  # Counter for the number of rejections\n",
    "alpha = 0.05  # Significance level\n",
    "num_simulations = 1000\n",
    "bias_values = []\n",
    "squared_error_values = []\n",
    "N = 50\n",
    "T = 20\n",
    "rho = 0.6\n",
    "true_beta1_value = 0\n",
    "\n",
    "\n",
    "for _ in range(num_simulations):\n",
    "\n",
    "    data = generate_ar1_data( N, T, rho)\n",
    "    states = data['state'].unique()\n",
    "\n",
    "    treatment_states = np.random.choice(states, size=len(states), replace=False)\n",
    "\n",
    "    # Assign treatment year to each treatment state, staggered between 1985 and 1995\n",
    "    treatment_years = np.random.choice(range(5, 15), size=len(treatment_states)//2, replace=True)\n",
    "    state_to_treatment_year = dict(zip(treatment_states, treatment_years))\n",
    "\n",
    "    # Add a treatment column to the DataFrame\n",
    "    data['TREATMENT'] = data.apply(lambda x: 1 if x['state'] in treatment_states and x['state'] in state_to_treatment_year and x['time'] >= state_to_treatment_year[x['state']] else 0, axis=1)\n",
    "\n",
    "\n",
    "    a = state_to_treatment_year.keys()\n",
    "\n",
    "    filtered_df = data[data['state'].isin(a)]\n",
    "    \n",
    "\n",
    "    # Separate pre-treatment and post-treatment data\n",
    "    pre_treatment_df = filtered_df[filtered_df['TREATMENT'] == 0]\n",
    "    post_treatment_df = filtered_df[filtered_df['TREATMENT'] == 1]\n",
    "\n",
    "    # Calculate the average residuals for pre-treatment and post-treatment periods\n",
    "    avg_residuals_pre_treatment = pre_treatment_df.groupby('state')['value'].mean().reset_index()\n",
    "    avg_residuals_post_treatment = post_treatment_df.groupby('state')['value'].mean().reset_index()\n",
    "\n",
    "    # Add a 'Treatment' column to indicate the treatment status for each period\n",
    "    avg_residuals_pre_treatment['Treatment'] = 0\n",
    "    avg_residuals_post_treatment['Treatment'] = 1\n",
    "\n",
    "    # Combine the two DataFrames into a new DataFrame\n",
    "    two_period_panel_df = pd.concat([avg_residuals_pre_treatment, avg_residuals_post_treatment], ignore_index=True)\n",
    "    \n",
    "    # Define the dependent and independent variables\n",
    "    \n",
    "    state_dummies = pd.get_dummies(two_period_panel_df['state'], prefix='state', drop_first = True)\n",
    "\n",
    "    # Convert state dummy variables to int\n",
    "    state_dummies = state_dummies.astype(int)\n",
    "    two_period_panel_df = pd.concat([two_period_panel_df, state_dummies], axis=1)\n",
    "\n",
    "    y = two_period_panel_df['value']\n",
    "    X = two_period_panel_df.drop(columns=['value'])\n",
    "    \n",
    "    # Add a constant term (intercept) to the independent variables\n",
    "    X = sm.add_constant(X)\n",
    "    \n",
    "    # Fit the regression model\n",
    "    model = sm.OLS(y, X).fit()\n",
    "\n",
    "    bias = model.params['Treatment'] - true_beta1_value\n",
    "    \n",
    "    bias_values.append(bias)\n",
    "\n",
    "    squared_error = (model.params['Treatment'] - true_beta1_value) ** 2\n",
    "    \n",
    "    # Check if null hypothesis for beta1 is rejected\n",
    "    if model.pvalues['Treatment'] < alpha:\n",
    "        reject_count += 1\n",
    "\n",
    "\n",
    "\n",
    "type1_error = reject_count / 1000\n",
    "\n",
    "average_bias = np.mean(bias_values)\n",
    "average_mse = np.mean(squared_error)\n",
    "\n",
    "\n",
    "# Print the number of rejections\n",
    "print(f\"Number of times null hypothesis is rejected for {rho}: {reject_count} out of 1000 simulations\")\n",
    "print(f\"Type 1 Error: {type1_error}\")\n",
    "print(f\"Bias for Coefficient of Treatment (True Value = {true_beta1_value}): {average_bias}\")\n",
    "print(f\"Average MSE for Coefficient of Treatment (True Value = {true_beta1_value}): {average_mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
