{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gzip\n",
    "\n",
    "# Specify the path to the compressed CSV file\n",
    "file_path = r'C:\\Users\\Biswajit Palit\\Downloads\\cps_00006.csv.gz'\n",
    "\n",
    "def cps_data(file_path):\n",
    "    # Use Pandas to read the compressed CSV file directly\n",
    "    # The compression parameter is set to 'gzip'\n",
    "    df = pd.read_csv(file_path, compression='gzip', header=0)\n",
    "\n",
    "    # Drop rows where INCWAGE is 99999999\n",
    "    df = df[(df['INCWAGE'] != 99999999) & (df['INCWAGE'] != 0) & (df['INCWAGE'] != 999)]\n",
    "    df['INCWAGE'] = np.log(df['INCWAGE'])\n",
    "    \n",
    "    df = df[(df['EDUC'] != 0) & (df['EDUC'] != 1)]\n",
    "\n",
    "    df = df[(df['YEAR'] >= 1980) & (df['YEAR'] <= 2000)]\n",
    "\n",
    "    dummy_df = pd.get_dummies(df['YEAR'], prefix='YEAR', drop_first=True)\n",
    "    df = pd.concat([df, dummy_df], axis=1)\n",
    "\n",
    "    def categorize_education(educ_code):\n",
    "        if educ_code <= 10:\n",
    "            return 'Up to Grade 10'\n",
    "        elif 10 < educ_code <= 70:\n",
    "            return 'High School'\n",
    "        elif 70 < educ_code <= 123:\n",
    "            return \"Master's Degree\"\n",
    "        else:\n",
    "            return 'Doctorate Degree'\n",
    "\n",
    "    # Apply the function to create a new 'Education_Category' column\n",
    "    df['Education_Category'] = df['EDUC'].apply(categorize_education)\n",
    "    df = pd.get_dummies(df, columns=['Education_Category'], prefix='', prefix_sep='', drop_first=True)\n",
    "\n",
    "    df = df[~((df['STATEFIP'] > 56) | (df['STATEFIP'] == 11))]\n",
    "\n",
    "    dummy_df = pd.get_dummies(df['STATEFIP'], prefix='STATEFIP', drop_first=True)\n",
    "    df = pd.concat([df, dummy_df], axis=1)\n",
    "\n",
    "    df = df[(df['AGE'] >= 25) & (df['AGE'] <= 50)]\n",
    "\n",
    "    df = df[df['SEX'] == 2]\n",
    "\n",
    "    boolean_columns = ['YEAR_1981', 'YEAR_1982',\n",
    "                       'YEAR_1983', 'YEAR_1984', 'YEAR_1985', 'YEAR_1986', 'YEAR_1987',\n",
    "                       'YEAR_1988', 'YEAR_1989', 'YEAR_1990', 'YEAR_1991', 'YEAR_1992',\n",
    "                       'YEAR_1993', 'YEAR_1994', 'YEAR_1995', 'YEAR_1996', 'YEAR_1997',\n",
    "                       'YEAR_1998', 'YEAR_1999', 'YEAR_2000', 'High School', \"Master's Degree\",\n",
    "                       'Up to Grade 10', 'STATEFIP_2', 'STATEFIP_4', 'STATEFIP_5',\n",
    "                       'STATEFIP_6', 'STATEFIP_8', 'STATEFIP_9', 'STATEFIP_10', 'STATEFIP_12',\n",
    "                       'STATEFIP_13', 'STATEFIP_15', 'STATEFIP_16', 'STATEFIP_17',\n",
    "                       'STATEFIP_18', 'STATEFIP_19', 'STATEFIP_20', 'STATEFIP_21',\n",
    "                       'STATEFIP_22', 'STATEFIP_23', 'STATEFIP_24', 'STATEFIP_25',\n",
    "                       'STATEFIP_26', 'STATEFIP_27', 'STATEFIP_28', 'STATEFIP_29',\n",
    "                       'STATEFIP_30', 'STATEFIP_31', 'STATEFIP_32', 'STATEFIP_33',\n",
    "                       'STATEFIP_34', 'STATEFIP_35', 'STATEFIP_36', 'STATEFIP_37',\n",
    "                       'STATEFIP_38', 'STATEFIP_39', 'STATEFIP_40', 'STATEFIP_41',\n",
    "                       'STATEFIP_42', 'STATEFIP_44', 'STATEFIP_45', 'STATEFIP_46',\n",
    "                       'STATEFIP_47', 'STATEFIP_48', 'STATEFIP_49', 'STATEFIP_50',\n",
    "                       'STATEFIP_51', 'STATEFIP_53', 'STATEFIP_54', 'STATEFIP_55',\n",
    "                       'STATEFIP_56']\n",
    "\n",
    "    # Convert True and False to 1 and 0 in the specified columns\n",
    "    df[boolean_columns] = df[boolean_columns].astype(int)\n",
    "\n",
    "    \n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "beta1_estimates = []\n",
    "reject_count = 0  # Counter for the number of rejections\n",
    "alpha = 0.05  # Significance level\n",
    "\n",
    "\n",
    "bias_values = []\n",
    "\n",
    "\n",
    "true_beta1_value = 0.02\n",
    "squared_error_values = []\n",
    "standard_error_values =[]\n",
    "num_simulations = 20\n",
    "file_path = r'C:\\Users\\Biswajit Palit\\Downloads\\cps_00006.csv.gz'\n",
    "df = cps_data(file_path)\n",
    "for _ in range(num_simulations):\n",
    "\n",
    "    data = df.copy()\n",
    "\n",
    "    model = smf.ols('INCWAGE ~ C(STATEFIP) + C(YEAR)', data=data)\n",
    "\n",
    "    # Fit the model\n",
    "    result = model.fit()\n",
    "\n",
    "    data['u_hat'] = result.resid\n",
    "\n",
    "    # Set your rho value\n",
    "    rho = 0.8\n",
    "    # Replace with your actual value\n",
    "\n",
    "    # Generate initial shock for the year 1980\n",
    "    data.loc[data['YEAR'] == 1980, 'shock'] = np.random.normal(size=len(data[data['YEAR'] == 1980]))\n",
    "\n",
    "    # Generate shocks for subsequent years\n",
    "    for year in range(1981, 2001):\n",
    "        # For each state, calculate the shock\n",
    "        for state in data['STATEFIP'].unique():\n",
    "            prev_shock = data[(data['YEAR'] == year - 1) & (data['STATEFIP'] == state)]['shock'].values\n",
    "            if len(prev_shock) >0:  # Check if previous year's data exists\n",
    "                current_shock = rho * prev_shock[0] + np.random.normal()\n",
    "                data.loc[(data['YEAR'] == year) & (data['STATEFIP'] == state), 'shock'] = current_shock\n",
    "\n",
    "\n",
    "    data['INCWAGE'] = data['INCWAGE'] - data['u_hat'] + data['shock']\n",
    "    \n",
    "    states = data['STATEFIP'].unique()\n",
    "    \n",
    "\n",
    "    # Randomly select half of the states to be in the treatment group\n",
    "    \n",
    "    treatment_states = np.random.choice(states, size=len(states)//2, replace=False)\n",
    "\n",
    "    # Assign treatment year to each treatment state, staggered between 1985 and 1995\n",
    "    treatment_years = np.random.choice(range(1985, 1995), size=len(treatment_states), replace=True)\n",
    "    state_to_treatment_year = dict(zip(treatment_states, treatment_years))\n",
    "\n",
    "    # Add a treatment column to the DataFrame\n",
    "    data['TREATMENT'] = data.apply(lambda x: 1 if x['STATEFIP'] in treatment_states and x['YEAR'] >= state_to_treatment_year[x['STATEFIP']] else 0, axis=1)\n",
    "    \n",
    "    data['outcome'] = data.apply(lambda x: x['INCWAGE']+(0.02) if x['TREATMENT'] == 1 else x['INCWAGE'], axis=1)\n",
    "\n",
    "    X = data[['High School', \"Master's Degree\", 'AGE']]\n",
    "    y = data['outcome']\n",
    "\n",
    "    X = sm.add_constant(X)\n",
    "\n",
    "    model = sm.OLS(y, X).fit()\n",
    "\n",
    "    # Obtain predicted values from the fitted model\n",
    "    y_pred = model.predict(X)\n",
    "\n",
    "    residuals = y - y_pred\n",
    "\n",
    "    data['Residuals'] = residuals\n",
    "\n",
    "    cps_agg = data.groupby(['STATEFIP', 'YEAR'])[['Residuals', 'TREATMENT']].mean().reset_index()\n",
    "\n",
    "    # One-hot encode STATEFIP and YEAR\n",
    "    dummy_df_state = pd.get_dummies(cps_agg['STATEFIP'], prefix='STATEFIP', drop_first=True)\n",
    "    dummy_df_year = pd.get_dummies(cps_agg['YEAR'], prefix='YEAR', drop_first=True)\n",
    "\n",
    "    # Concatenate the dummy variables with the original DataFrame\n",
    "    cps_agg = pd.concat([cps_agg, dummy_df_state, dummy_df_year], axis=1)\n",
    "\n",
    "    # Convert True and False to 1 and 0 in the specified columns\n",
    "    boolean_columns = ['STATEFIP_2', 'STATEFIP_4', 'STATEFIP_5', 'STATEFIP_6', 'STATEFIP_8', 'STATEFIP_9',\n",
    "                        'STATEFIP_10', 'STATEFIP_12', 'STATEFIP_13', 'STATEFIP_15', 'STATEFIP_16', 'STATEFIP_17',\n",
    "                        'STATEFIP_18', 'STATEFIP_19', 'STATEFIP_20', 'STATEFIP_21', 'STATEFIP_22', 'STATEFIP_23',\n",
    "                        'STATEFIP_24', 'STATEFIP_25', 'STATEFIP_26', 'STATEFIP_27', 'STATEFIP_28', 'STATEFIP_29',\n",
    "                        'STATEFIP_30', 'STATEFIP_31', 'STATEFIP_32', 'STATEFIP_33', 'STATEFIP_34', 'STATEFIP_35',\n",
    "                        'STATEFIP_36', 'STATEFIP_37', 'STATEFIP_38', 'STATEFIP_39', 'STATEFIP_40', 'STATEFIP_41',\n",
    "                        'STATEFIP_42', 'STATEFIP_44', 'STATEFIP_45', 'STATEFIP_46', 'STATEFIP_47', 'STATEFIP_48',\n",
    "                        'STATEFIP_49', 'STATEFIP_50', 'STATEFIP_51', 'STATEFIP_53', 'STATEFIP_54', 'STATEFIP_55',\n",
    "                        'STATEFIP_56', 'YEAR_1981', 'YEAR_1982', 'YEAR_1983', 'YEAR_1984', 'YEAR_1985', 'YEAR_1986',\n",
    "                        'YEAR_1987', 'YEAR_1988', 'YEAR_1989', 'YEAR_1990', 'YEAR_1991', 'YEAR_1992', 'YEAR_1993',\n",
    "                        'YEAR_1994', 'YEAR_1995', 'YEAR_1996', 'YEAR_1997', 'YEAR_1998', 'YEAR_1999', 'YEAR_2000']\n",
    "\n",
    "    cps_agg[boolean_columns] = cps_agg[boolean_columns].astype(int)\n",
    "\n",
    "    data = cps_agg.copy()\n",
    "\n",
    "    X = data['TREATMENT'] # plus any other control variables\n",
    "    X = sm.add_constant(X)\n",
    "    Y = data['Residuals'] # Replace 'outcome' with your dependent variable\n",
    "    model = sm.OLS(Y, X).fit(cov_type='cluster', cov_kwds={'groups': data['STATEFIP'].astype(str)})\n",
    "\n",
    "    bias = model.params['TREATMENT'] - true_beta1_value\n",
    "    \n",
    "    bias_values.append(bias)\n",
    "\n",
    "    squared_error = (model.params['TREATMENT'] - true_beta1_value) ** 2\n",
    "\n",
    "    \n",
    "    standard_error = model.bse['TREATMENT']\n",
    "    standard_error_values.append(standard_error)\n",
    "    beta1_estimates.append(model.params['TREATMENT'])\n",
    "    \n",
    "    \n",
    "    # Check if null hypothesis for beta1 is rejected\n",
    "    if model.pvalues['TREATMENT'] < alpha:\n",
    "        reject_count += 1\n",
    "\n",
    "\n",
    "type1_error = reject_count / num_simulations\n",
    "\n",
    "average_bias = np.mean(bias_values)\n",
    "average_mse = np.mean(squared_error)   \n",
    "average_rmse = np.sqrt(average_mse)  \n",
    "average_standard_error = np.mean(standard_error_values)   \n",
    "\n",
    "std_error_beta_distribution = np.std(beta1_estimates)\n",
    "\n",
    "\n",
    "average_bias = np.mean(bias_values)\n",
    "average_mse = np.mean(squared_error)\n",
    "\n",
    "\n",
    "# Print the number of rejections\n",
    "print(f\"Number of times null hypothesis is rejected : {reject_count} out of {num_simulations} simulations\")\n",
    "print(f\"Power of the test: {type1_error * 100} %\")\n",
    "print(f\"Bias for Coefficient of Treatment (True Value = {true_beta1_value}): {average_bias}\")\n",
    "print(f\"MSE for Coefficient of Treatment (True Value = {true_beta1_value}): {average_mse}\")\n",
    "\n",
    "sns.histplot(beta1_estimates, kde=True)\n",
    "plt.xlabel('Beta1 Estimates')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Beta1 Estimates')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
