{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'Monte_Carlo_AR1_code'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mMonte_Carlo_AR1_code\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m generate_staggered_law_ar1_data\n\u001b[0;32m      8\u001b[0m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(\u001b[38;5;241m42\u001b[39m) \n\u001b[0;32m     10\u001b[0m beta1_estimates \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'Monte_Carlo_AR1_code'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from Monte_Carlo_AR1_code import generate_staggered_law_ar1_data\n",
    "\n",
    "np.random.seed(42) \n",
    "\n",
    "beta1_estimates = []\n",
    "\n",
    "reject_count = 0  # Counter for the number of rejections\n",
    "alpha = 0.05  # Significance level\n",
    "num_simulations = 1000\n",
    "bias_values = []\n",
    "squared_error_values = []\n",
    "N = 50\n",
    "T = 20\n",
    "rho = 0\n",
    "num_individuals = 20\n",
    "\n",
    "true_beta1_value = 0\n",
    "standard_error_values = []\n",
    "\n",
    "bias_values = []\n",
    "\n",
    "\n",
    "\n",
    "for _ in range(1000):\n",
    "    data = generate_staggered_law_ar1_data( N, T, rho, num_individuals)\n",
    "    states = data['state'].unique()\n",
    "\n",
    "    # Randomly select half of the states to be in the treatment group\n",
    "    \n",
    "    treatment_states = np.random.choice(states, size=len(states)//2, replace=False)\n",
    "\n",
    "    # Assign treatment year to each treatment state, staggered between 1985 and 1995\n",
    "    treatment_years = np.random.choice(range(5, 15), size=len(treatment_states), replace=True)\n",
    "    state_to_treatment_year = dict(zip(treatment_states, treatment_years))\n",
    "\n",
    "    # Add a treatment column to the DataFrame\n",
    "    data['TREATMENT'] = data.apply(lambda x: 1 if x['state'] in treatment_states and x['time'] >= state_to_treatment_year[x['state']] else 0, axis=1)\n",
    "\n",
    "    # Step 3: Perform the OLS regression\n",
    "    X = data[['TREATMENT', 'state_2', 'state_3', 'state_4', 'state_5',\n",
    "       'state_6', 'state_7', 'state_8', 'state_9', 'state_10', 'state_11',\n",
    "       'state_12', 'state_13', 'state_14', 'state_15', 'state_16', 'state_17',\n",
    "       'state_18', 'state_19', 'state_20', 'state_21', 'state_22', 'state_23',\n",
    "       'state_24', 'state_25', 'state_26', 'state_27', 'state_28', 'state_29',\n",
    "       'state_30', 'state_31', 'state_32', 'state_33', 'state_34', 'state_35',\n",
    "       'state_36', 'state_37', 'state_38', 'state_39', 'state_40', 'state_41',\n",
    "       'state_42', 'state_43', 'state_44', 'state_45', 'state_46', 'state_47',\n",
    "       'state_48', 'state_49', 'state_50', 'time_1', 'time_2', 'time_3',\n",
    "       'time_4', 'time_5', 'time_6', 'time_7', 'time_8', 'time_9', 'time_10',\n",
    "       'time_11', 'time_12', 'time_13', 'time_14', 'time_15', 'time_16',\n",
    "       'time_17', 'time_18', 'time_19']] # plus any other control variables\n",
    "    X = sm.add_constant(X)\n",
    "    Y = data['value'] # Replace 'outcome' with your dependent variable\n",
    "    model = sm.OLS(Y, X).fit()\n",
    "\n",
    "    bias = model.params['TREATMENT'] - true_beta1_value\n",
    "    \n",
    "    bias_values.append(bias)\n",
    "\n",
    "    squared_error = (model.params['TREATMENT'] - true_beta1_value) ** 2\n",
    "\n",
    "    \n",
    "    standard_error = model.bse['TREATMENT']\n",
    "    standard_error_values.append(standard_error)\n",
    "    beta1_estimates.append(model.params['TREATMENT'])\n",
    "    \n",
    "    \n",
    "    # Check if null hypothesis for beta1 is rejected\n",
    "    if model.pvalues['TREATMENT'] < alpha:\n",
    "        reject_count += 1\n",
    "\n",
    "\n",
    "type1_error = reject_count / 1000\n",
    "\n",
    "average_bias = np.mean(bias_values)\n",
    "average_mse = np.mean(squared_error)   \n",
    "average_rmse = np.sqrt(average_mse)  \n",
    "average_standard_error = np.mean(standard_error_values)   \n",
    "\n",
    "std_error_beta_distribution = np.std(beta1_estimates)\n",
    "\n",
    "sns.histplot(beta1_estimates, kde=True)\n",
    "plt.xlabel('Beta1 Estimates')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Beta1 Estimates')\n",
    "plt.show()\n",
    "\n",
    "# Calculate the confidence interval\n",
    "confidence_interval = (\n",
    "    np.mean(beta1_estimates) - 1.96 * std_error_beta_distribution,\n",
    "    np.mean(beta1_estimates) + 1.96 * std_error_beta_distribution\n",
    ")\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(beta1_estimates, bins=30, density=True, color='blue', alpha=0.7)\n",
    "plt.axvline(np.mean(beta1_estimates), color='red', linestyle='dashed', linewidth=2, label='Mean Estimate')\n",
    "plt.axvline(confidence_interval[0], color='green', linestyle='dashed', linewidth=2, label='95% CI')\n",
    "plt.axvline(confidence_interval[1], color='green', linestyle='dashed', linewidth=2)\n",
    "plt.xlabel('Treatment Coefficient Estimate')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Distribution and Confidence Interval of Treatment Coefficient')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Print the number of rejections\n",
    "# Print the number of rejections\n",
    "print(f\"Number of times null hypothesis is rejected for : {reject_count} out of 1000 simulations\")\n",
    "print(f\"Type 1 Error: {type1_error}\")\n",
    "print(f\"Bias for Coefficient of Treatment (True Value = {true_beta1_value}): {average_bias}\")\n",
    "print(f\"MSE for Coefficient of Treatment (True Value = {true_beta1_value}): {average_mse}\")\n",
    "print(f\"Average RMSE for Coefficient of Treatment (True Value = {true_beta1_value}): {average_rmse}\")\n",
    "print(f'The confidence interval is {confidence_interval[0] , {confidence_interval[1]}}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
